---
layout: post
title: Week 9
---

### Jumping into Week #10 already?
Week 9 is already coming to an end. I cannot believe how far we've gotten into our internship.  The experience has been rich, and I've learned quite a lot about the general research development stages.  Not only that, but also with all the things inside and out of JavaScript, node.js, and WebRTC. The experiences have been frustrating in some areas where I think my weaknesses were.  There were some bugs or logical errors that I could not get around to solve or fix.  Thankfully for my team, they were able to help out with the frustrations I had for some of my tasks.  This truly makes me realize that (I'm aware of this, but never have witnessed it myself) that it's not possible to do every task by yourself and succeed. (With an exception of truly gifted individuals).. There's always going to be some tasks where I won't be able to solve or finish it successfully.  I'd like to thank my team for their hard work on some of these solutions in the past few weeks!  It's also a benefit to see the coding solutions the others on my team has made and for me to look over their code and see where I did wrong with my code.  This has been a great learning experience, as well as a big leap over the class knowledge that I've only known with no real world connections.  This Research project opened the door into the real world programming problems and solutions as well.  I am glad to make this leap, and I hope to continue striving for the best capabilities out of myself as a tech worker. 

### Merging Azure/WSA All in one project
So last week, I spent majority of my time trying to merge both Azure and WSA into one project. This week, there were apparently a couple bugs that I never really realized that got their ways into the project.  My teammate, Norman, helped me fix it and he built the function to be cleaner and concise.  I spent some time polishing it up, but I thank Norman for contributing more of his time cleaning it up and fixing the bugs that I would have never be able to fix on my own due to my inexperiences with using JavaScript and especially hunting bugs to the "no mans land."  The merge project is mostly done. It's missing a couple "new" features that we've implemented in the other projects. Bits here and there.  If we have more time, we probably will look into adding these new features from other projects (A/B) into the Merge project.

### AB Testing
As we are shifting from our development processes and into usability testing and to gather feedback from the users who use our browser apps.  Emelia brought in one person to use as a pilot tester for the AB testing environment that she has worked on more than I did.  We greatly appreciate the feedback we got from her participant for the AB testing environment.  Due to the feedback, she made a couple minor changes.  This is also where we were looking into getting the new features added.  There are two environments: A & B.  A is more focused on the captioning itself.  B is more focused on the transcript itself.  With the captioning project, the captions are shown at bottom of each video participant's screen.  The new feature our mentor/team has suggested was to add a "stretched" full screen caption overlay that you could double click to make it expand or shrink.  The captions in their default state only show 2 rows.  When you expand, it will depend on the size of video and based on that it could display anywhere between 10 rows and 30ish rows.  This depends on the display resolution as well if I recall right. We were also exploring to add another feature, a username display on top left corner of every video participant to indicate their names.  Theoretically speaking, if you were to read the transcript (it already has usernames set up) you wouldn't know who is who.  With the usernames added to the video participant's screen, it helps people identify the speaker's names and when they read the transcripts with their names on it, they would know who the names were referring to whoever is in their video screen (if you were meeting with some people for the first time, you don't know their names, this becomes useful in that situation).  I developed some code initially, but Emelia helped move it forward to get the usernames to show up on video screens.  This is one of the frustrations I had as a personal task, nevertheless, I am grateful for my team to be able to step in and help me solve this on a faster pace.  The third new feature was to add a "Download Transcript" button in the B environment which has a transcript.  I am still working on it to this moment.  There are a couple bugs to hunt down.  It is able to download a new text file, but inside the text file, it keeps on returning either null or undefined for several different methods and implementations that I've tried to do.  Hope to see that we will have better luck tracking this bug down next week. That's all for now! Onwards to Week #10, the final week. I cannot believe how fast time has gone to the point next week is the final week! See you then.

